# ğŸ“ MiniMeter - MÃ¼lakat "Cheat Sheet"

Bu belgeyi mÃ¼lakat sÄ±rasÄ±nda aÃ§Ä±k tut. HÄ±zlÄ± cevaplar ve "Show & Tell" senaryolarÄ± iÃ§erir.

---

## ğŸš€ 1. Elevator Pitch (Projeyi Anlat)
**Soru:** "Bize projeden bahset?"

> "MiniMeter, **LLM destekli bir enerji faturasÄ± iÅŸleme pipeline'Ä±**. Start-uplarÄ±n yaÅŸadÄ±ÄŸÄ± 'messy data' problemini Ã§Ã¶zmek iÃ§in tasarlandÄ±.
>
> KullanÄ±cÄ± faturayÄ± sisteme verir, sistem asenkron olarak:
> 1. FaturayÄ± **Cloud Storage**'a yedekler (Audit iÃ§in).
> 2. **Gemini 2.0 Flash** ile veriyi Ã§Ä±kartÄ±r (Extraction).
> 3. **Pydantic** ile veriyi doÄŸrular (Validation).
> 4. SonuÃ§larÄ± operasyonel analiz iÃ§in **Cloud SQL**'e ve raporlama iÃ§in **BigQuery**'ye yazar.
>
> Mimari olarak **Event-Driven Microservices** yapÄ±sÄ±nÄ± seÃ§tim Ã§Ã¼nkÃ¼ API'nin hÄ±zlÄ± yanÄ±t vermesi ve aÄŸÄ±r iÅŸlerin (LLM) arka planda Ã¶lÃ§eklenebilmesi gerekiyordu."

---

## ğŸ–¥ 2. Show & Tell (Kod GÃ¶sterme)

Ekran paylaÅŸÄ±mÄ± istenirse bu sÄ±rayla git:

### A. "En Temiz Kodum" -> `worker/main.py`
**Vurgula:**
- **Job Lifecycle:** `PENDING` -> `RUNNING` -> `SUCCEEDED` (SatÄ±r ~70 `update_job`)
- **Idempotency:** AynÄ± mesaj iki kere gelirse tekrar iÅŸlememesi (`get_job_info` kontrolÃ¼).
- **ORM Usage:** GÃ¼venli DB iÅŸlemleri (`db.query(...)`, `db.add(...)`).

### B. "Mimari KararÄ±m" -> `shared/database.py` & `orm_models.py`
**Vurgula:**
- **Context Manager:** `with get_db() as db:` yapÄ±sÄ± ile otomatik commit/rollback.
- **Shared Models:** API ve Worker aynÄ± modelleri kullanÄ±yor, duplication yok.

### C. "LLM Entegrasyonu" -> `worker/llm.py` & `eval/run.py`
**Vurgula:**
- **Provider Context:** LLM'e "Bu bir PG&E faturasÄ±" diyerek accuracy arttÄ±rma.
- **Eval Set:** Kodunu deÄŸiÅŸtirdiÄŸimde accuracy bozulmasÄ±n diye yazdÄ±ÄŸÄ±m test seti (`eval/bills/`).

---

## ğŸ›¡ 3. Zor Sorular & Cevaplar

| Soru | Cevap (KÄ±sa) | Detay |
|------|--------------|-------|
| **Neden Pub/Sub?** | Decoupling & Reliability | "API dÃ¼ÅŸse bile mesajlar kaybolmaz (durability). Worker sayÄ±sÄ±nÄ± arttÄ±rarak processing hÄ±zÄ±nÄ± scale edebilirim." |
| **Neden GCS?** | Unstructured Data Storage | "VeritabanÄ± text/blob saklamak iÃ§in pahalÄ±. Orijinal faturayÄ± GCS'de tutup sadece linkini DB'ye koymak best practice." |
| **Neden ORM?** | Security & Maintainability | "Raw SQL injection'a aÃ§Ä±k olabilir. SQLAlchemy type safety saÄŸlÄ±yor ve DB deÄŸiÅŸimini (Postgres -> MySQL) kolaylaÅŸtÄ±rÄ±yor." |
| **LLM YanlÄ±ÅŸ Okursa?** | Pydantic Validation | "LLM Ã§Ä±ktÄ±sÄ±nÄ± `BillNormalized` ÅŸemasÄ± ile zorluyorum. Format yanlÄ±ÅŸsa kod hata fÄ±rlatÄ±r ve job `FAILED` olur." |
| **Scale Edersen?** | Caching + Async | "LLM Ã§aÄŸrÄ±larÄ± iÃ§in Redis cache eklerim. Worker sayÄ±sÄ±nÄ± horizontal scale ederim (K8s/Cloud Run)." |

---

## ğŸ“Š 4. Mimari Åema (GÃ¶zÃ¼nÃ¼n Ã–nÃ¼nde Olsun)

```mermaid
graph LR
    User[User/Client] -->|POST /agent/run| API[Cloud Run API]
    API -->|Create Job| DB[(Cloud SQL)]
    API -->|Publish Event| PS[Pub/Sub]
    
    PS -->|Pull Job| Worker[Worker Service]
    Worker -->|Fetch State| DB
    
    subgraph Processing Loop
        Worker -->|Upload| GCS[Cloud Storage]
        Worker -->|Extract| LLM[Gemini 2.0]
        Worker -->|Insert| BQ[BigQuery]
    end
    
    Worker -->|Update Status| DB
```

---

## ğŸ“ˆ 5. Future Scaling Roadmap (10 â†’ 10k Customers)

"Bu sistemi nasÄ±l 10,000 mÃ¼ÅŸteriye scale edersin?" sorusuna verilecek yapÄ±landÄ±rÄ±lmÄ±ÅŸ cevap.

### A. Infrastructure (Compute)
*   **Åimdi:** Cloud Run (API) + VM (veya tek Worker).
*   **Next Step:** **Cloud Run Jobs** veya **K8s (GKE)**.
    *   Worker'larÄ± stateless hale getirdik, bu yÃ¼zden yatay olarak (horizontal scaling) kolayca N adet worker Ã§alÄ±ÅŸtÄ±rabiliriz.
    *   Job queue partitioning: Customer ID'ye gÃ¶re farklÄ± Pub/Sub topic'lerine bÃ¶lerek "noisy neighbor" problemini Ã¶nleriz.

### B. Database (Storage)
*   **Åimdi:** Tek Cloud SQL instance.
*   **Next Step:** **Connection Pooling** (PgBouncer) + **Read Replicas**.
    *   Yazma iÅŸlemi (INSERT) asenkron olduÄŸu iÃ§in DB'yi kilitlemez ama okuma iÅŸlemleri (Dashboard) artarsa Read Replica ekleriz.
    *   Analitik sorgular zaten BigQuery'de olduÄŸu iÃ§in ana DB rahat.

### C. LLM Optimization (Cost & Latency)
*   **Åimdi:** Her fatura iÃ§in Gemini API Ã§aÄŸrÄ±sÄ± (~2sn).
*   **Next Step:** **Caching** + **Batching**.
    *   **Semantic Caching:** AynÄ± faturayÄ± tekrar gÃ¶nderirlerse embedding kontrolÃ¼ ile cache'den dÃ¶neriz.
    *   **Fine-tuning:** SÄ±k gelen fatura formatlarÄ± (Ã¶rn: PG&E) iÃ§in daha kÃ¼Ã§Ã¼k ve hÄ±zlÄ± bir model (Gemini Flash veya Llama 3) fine-tune edip maliyeti %90 dÃ¼ÅŸÃ¼rÃ¼rÃ¼z.

### D. Architecture (Reliability)
*   **Åimdi:** Tek region.
*   **Next Step:** **Multi-Region** + **Dead Letter Queues (DLQ)**.
    *   Pub/Sub'da 5 kez baÅŸarÄ±sÄ±z olan iÅŸleri DLQ'ya atÄ±p, insan incelemesine (human-in-the-loop) sunan bir dashboard ekleriz.

---

## âš¡ï¸ 6. Demo Ä°sterlerse

HazÄ±r komutlar:

**1. Job BaÅŸlat:**
```bash
curl -X POST "https://minimeter-api-787646377501.us-central1.run.app/agent/run?utility_account_id=1"
```

**2. Sonucu GÃ¶ster:**
```bash
# ID'yi gÃ¼ncelle: /agent/result/10
curl https://minimeter-api-787646377501.us-central1.run.app/agent/result/10
```
